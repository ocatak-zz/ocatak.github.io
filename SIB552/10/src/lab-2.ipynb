{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11. Hafta Lab-2: Malware Images\n",
    "## BGM 565: Siber Güvenlik için Makine Öğrenme Yöntemleri\n",
    "## İstanbul Şehir Üni. - Bilgi Güvenliği Müh.\n",
    "### Dr. Ferhat Özgür Çatak\n",
    "Bu lab çalışması kapsamında Android zararlı yazılımlarının image haline getirilip sınıflandırma modeli oluşturulması anlatılacaktır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
    "from keras.utils import np_utils\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dense\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import callbacks\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model\n",
    "2 adet convolution katmanı ve tek katman sinir ağ modeli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "labels = []\n",
    "\n",
    "class LeNet:\n",
    "    @staticmethod\n",
    "    def build(width, height, depth, classes):\n",
    "        # initialize the model\n",
    "        model = Sequential()\n",
    "        inputShape = (height, width, depth)\n",
    "        \n",
    "        '''\n",
    "        # if we are using \"channels first\", update the input shape\n",
    "        if K.image_data_format() == \"channels_first\":\n",
    "            inputShape = (depth, height, width)\n",
    "        '''\n",
    "        # first set of CONV => RELU => POOL layers\n",
    "        model.add(Conv2D(10, (5, 5), padding=\"same\",input_shape=inputShape))\n",
    "        model.add(Activation(\"tanh\"))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "        \n",
    "        # second set of CONV => RELU => POOL layers\n",
    "        model.add(Conv2D(20, (5, 5), padding=\"same\"))\n",
    "        model.add(Activation(\"tanh\"))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "        # first (and only) set of FC => RELU layers\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(30))\n",
    "        model.add(Activation(\"sigmoid\"))\n",
    "\n",
    "        # softmax classifier\n",
    "        model.add(Dense(classes))\n",
    "        model.add(Activation(\"softmax\"))\n",
    "\n",
    "        # return the constructed network architecture\n",
    "        return model\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image dosyalarını okuyarak numpy array'e dönüştür\n",
    "f = open(\"results.txt\",\"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/user/Documents/dataset/pngs/d7de0ee80aa16beca37ccbbc30031995.png\n",
      "C:/Users/user/Documents/dataset/pngs/7282c48bdad45f3861edd8244061c26e.png\n",
      "C:/Users/user/Documents/dataset/pngs/e368fb1d80bbf24fdfb4ebae7806c885.png\n",
      "C:/Users/user/Documents/dataset/pngs/f25e3352735aa210906527adf1140980.png\n",
      "C:/Users/user/Documents/dataset/pngs/ee1bcb0d5036b4ba72036f79c538c8b1.png\n",
      "C:/Users/user/Documents/dataset/pngs/9a031f2f5022fae13849b566a1b89579.png\n",
      "C:/Users/user/Documents/dataset/pngs/6797aebf0ff789fbf37f543acc126a98.png\n",
      "C:/Users/user/Documents/dataset/pngs/a14e9bfc6dfdfa6fca36a7aefe7590d1.png\n",
      "C:/Users/user/Documents/dataset/pngs/d44cda7feb8e37d7373fbca2199c6820.png\n",
      "C:/Users/user/Documents/dataset/pngs/20d4b9eb9377c499917c4d69bf4ccebe.png\n",
      "C:/Users/user/Documents/dataset/pngs/43680d1914f28e14c90436e1d42984e2.png\n",
      "C:/Users/user/Documents/dataset/pngs/acfce0995b14ff44eab18a90ba46c292.png\n",
      "C:/Users/user/Documents/dataset/pngs/825fc8e2c5888e31d600a7b6ad3f0b57.png\n",
      "C:/Users/user/Documents/dataset/pngs/9a6691f0ae3dcbef0110fbf6ae6ed45b.png\n",
      "C:/Users/user/Documents/dataset/pngs/63d4fc65f9ce6db89e6f4b8162f2fa91.png\n",
      "C:/Users/user/Documents/dataset/pngs/d774ebb94991b252d7723894e7d00e92.png\n",
      "C:/Users/user/Documents/dataset/pngs/844ba4a0564ca7ff99e5c85caa926ad4.png\n",
      "C:/Users/user/Documents/dataset/pngs/5aceb560ac3f56956f2f4f29ad227a91.png\n",
      "C:/Users/user/Documents/dataset/pngs/fb04e52c9c93e65f980876c767d003dc.png\n",
      "C:/Users/user/Documents/dataset/pngs/a5a36007625371c5c828b938796578ca.png\n",
      "C:/Users/user/Documents/dataset/pngs/3b1c1d476ea80bd58f3eb1bbb32c42fa.png\n",
      "C:/Users/user/Documents/dataset/pngs/48ab87de9de719a08f3f70aef4642c02.png\n",
      "C:/Users/user/Documents/dataset/pngs/b98988b42f5e3ec92a557a1f31df333d.png\n",
      "C:/Users/user/Documents/dataset/pngs/bc5d697e9217fe06194e565c4e031517.png\n",
      "C:/Users/user/Documents/dataset/pngs/1c8b5566f6ba1198b8110b6179f608ca.png\n",
      "C:/Users/user/Documents/dataset/pngs/fc27a200f241d42a46786adea05b0339.png\n",
      "C:/Users/user/Documents/dataset/pngs/32dca26eee9b8bede8c27278a77f031b.png\n",
      "C:/Users/user/Documents/dataset/pngs/7bf7e872ec8e11364a11dfbcd6ffb209.png\n",
      "C:/Users/user/Documents/dataset/pngs/633e34627fc5068c52df2314d0dcf735.png\n",
      "C:/Users/user/Documents/dataset/pngs/64e374807d87102cfc27489a91f8a13d.png\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "iter = 0\n",
    "for line in f:\n",
    "    iter += 1\n",
    "    if iter > 30:\n",
    "        continue\n",
    "    c,fname = line.split(\",\")\n",
    "    fpath = \"C:/Users/user/Documents/dataset/pngs/\"+ fname.strip()\n",
    "    \n",
    "    print(fpath.strip())\n",
    "    i = cv2.imread(fpath)\n",
    "    image = cv2.resize(i, (2048,512))\n",
    "    image = img_to_array(image)\n",
    "    data.append(image)\n",
    "\n",
    "    labels.append(c)\n",
    "\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data.shape (30, 512, 2048, 3)\n",
      "labels.shape (30,)\n"
     ]
    }
   ],
   "source": [
    "data = np.array(data, dtype=\"float\")\n",
    "labels = np.array(labels)\n",
    "\n",
    "print('data.shape',data.shape)\n",
    "print('labels.shape',labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeli oluştur\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\user\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 512, 2048, 10)     760       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 512, 2048, 10)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 256, 1024, 10)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 256, 1024, 20)     5020      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 256, 1024, 20)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 128, 512, 20)      0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1310720)           0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 30)                39321630  \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 30)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 124       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 39,327,534\n",
      "Trainable params: 39,327,534\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoder.fit(labels)\n",
    "encoded_Y = encoder.transform(labels)\n",
    "dummy_Y = np_utils.to_categorical(encoded_Y)\n",
    "y = encoded_Y\n",
    "model = LeNet.build(width=2048, height=512, depth=3, classes=dummy_Y.shape[1])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeli yükle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath=\"03-malware-detection.hdf5\"\n",
    "\n",
    "#model.load_weights(filepath)\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer='adam', metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 27 samples, validate on 3 samples\n",
      "Epoch 1/1\n",
      "27/27 [==============================] - 130s 5s/step - loss: 1.4507 - acc: 0.4074 - val_loss: 0.5164 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00001: loss improved from 1.62234 to 1.45070, saving model to 03-malware-detection.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x19ed5fc1390>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(data, dummy_Y, verbose=1, epochs=1, batch_size=5, validation_split=0.1 , callbacks=callbacks_list )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model performansı"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = model.predict_classes(data)\n",
    "cm = confusion_matrix(encoded_Y, y_hat)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
