{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11. Hafta Lab-2: Malware Images\n",
    "## BGM 565: Siber Güvenlik için Makine Öğrenme Yöntemleri\n",
    "## İstanbul Şehir Üni. - Bilgi Güvenliği Müh.\n",
    "### Dr. Ferhat Özgür Çatak\n",
    "Bu lab çalışması kapsamında Android zararlı yazılımlarının image haline getirilip sınıflandırma modeli oluşturulması anlatılacaktır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
    "from keras.utils import np_utils\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dense\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import callbacks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model\n",
    "2 adet convolution katmanı ve tek katman sinir ağ modeli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "labels = []\n",
    "\n",
    "class LeNet:\n",
    "    @staticmethod\n",
    "    def build(width, height, depth, classes):\n",
    "        # initialize the model\n",
    "        model = Sequential()\n",
    "        inputShape = (height, width, depth)\n",
    "        \n",
    "        '''\n",
    "        # if we are using \"channels first\", update the input shape\n",
    "        if K.image_data_format() == \"channels_first\":\n",
    "            inputShape = (depth, height, width)\n",
    "        '''\n",
    "        # first set of CONV => RELU => POOL layers\n",
    "        model.add(Conv2D(10, (5, 5), padding=\"same\",input_shape=inputShape))\n",
    "        model.add(Activation(\"tanh\"))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "        \n",
    "        # second set of CONV => RELU => POOL layers\n",
    "        model.add(Conv2D(20, (5, 5), padding=\"same\"))\n",
    "        model.add(Activation(\"tanh\"))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "        # first (and only) set of FC => RELU layers\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(30))\n",
    "        model.add(Activation(\"sigmoid\"))\n",
    "\n",
    "        # softmax classifier\n",
    "        model.add(Dense(classes))\n",
    "        model.add(Activation(\"softmax\"))\n",
    "\n",
    "        # return the constructed network architecture\n",
    "        return model\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image dosyalarını okuyarak numpy array'e dönüştür\n",
    "f = open(\"results.txt\",\"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/user/Documents/dataset/pngs/f25e3352735aa210906527adf1140980.png\n",
      "C:/Users/user/Documents/dataset/pngs/ee1bcb0d5036b4ba72036f79c538c8b1.png\n",
      "C:/Users/user/Documents/dataset/pngs/9a031f2f5022fae13849b566a1b89579.png\n",
      "C:/Users/user/Documents/dataset/pngs/d7de0ee80aa16beca37ccbbc30031995.png\n",
      "C:/Users/user/Documents/dataset/pngs/e368fb1d80bbf24fdfb4ebae7806c885.png\n",
      "C:/Users/user/Documents/dataset/pngs/d44cda7feb8e37d7373fbca2199c6820.png\n",
      "C:/Users/user/Documents/dataset/pngs/6797aebf0ff789fbf37f543acc126a98.png\n",
      "C:/Users/user/Documents/dataset/pngs/a14e9bfc6dfdfa6fca36a7aefe7590d1.png\n",
      "C:/Users/user/Documents/dataset/pngs/7282c48bdad45f3861edd8244061c26e.png\n",
      "C:/Users/user/Documents/dataset/pngs/7ed5e8f3de77bf3d88896fbc756f4ee4.png\n",
      "C:/Users/user/Documents/dataset/pngs/531882c30198ae24329563a64e3199cd.png\n",
      "C:/Users/user/Documents/dataset/pngs/df0223ca501823514a3d7a0025c1a0da.png\n",
      "C:/Users/user/Documents/dataset/pngs/8a72124709dd0cd555f01effcbb42078.png\n",
      "C:/Users/user/Documents/dataset/pngs/59e5c759e942f45348d9545fc00ec17b.png\n",
      "C:/Users/user/Documents/dataset/pngs/7d135accb168571389fc0c72ed2d30f1.png\n",
      "C:/Users/user/Documents/dataset/pngs/a8ca4a9b7c03fdb33101c55de4b22a4c.png\n",
      "C:/Users/user/Documents/dataset/pngs/9a84fa875dc76f5a3ab1047eed249985.png\n",
      "C:/Users/user/Documents/dataset/pngs/1cfe944162e3cfc9f29322bd19026f99.png\n",
      "C:/Users/user/Documents/dataset/pngs/c96673a84bf26cc3acd063596b6644d2.png\n",
      "C:/Users/user/Documents/dataset/pngs/42734768046ebf99c0201da7192cb29e.png\n",
      "C:/Users/user/Documents/dataset/pngs/86bfff26de541d564c801f43c8efc11a.png\n",
      "C:/Users/user/Documents/dataset/pngs/dc42c2991f95b2ebd6b356a04513f45a.png\n",
      "C:/Users/user/Documents/dataset/pngs/af67396c337cb588755a6bc1bed49ee7.png\n",
      "C:/Users/user/Documents/dataset/pngs/a6e862c686ff2e9b3222395a4bf243d0.png\n",
      "C:/Users/user/Documents/dataset/pngs/23f30e96b6e28a4963055887ba6c4e44.png\n",
      "C:/Users/user/Documents/dataset/pngs/f9b9d32e67540e80df1f5bc4d62ab0ff.png\n",
      "C:/Users/user/Documents/dataset/pngs/44112b7b4c5fec84fb1c3ad9e66d326c.png\n",
      "C:/Users/user/Documents/dataset/pngs/7c267a8d60afb1a7e315924080655bf7.png\n",
      "C:/Users/user/Documents/dataset/pngs/b3b5872d8e0e3bbbd782f8b7df4259e2.png\n",
      "C:/Users/user/Documents/dataset/pngs/3d3eac7909186c86ae7f07c42fd61b1e.png\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "iter = 0\n",
    "for line in f:\n",
    "    iter += 1\n",
    "    if iter > 30:\n",
    "        continue\n",
    "    c,fname = line.split(\",\")\n",
    "    fpath = \"C:/Users/user/Documents/dataset/pngs/\"+ fname.strip()\n",
    "    \n",
    "    print(fpath.strip())\n",
    "    i = cv2.imread(fpath)\n",
    "    image = cv2.resize(i, (2048,512))\n",
    "    image = img_to_array(image)\n",
    "    data.append(image)\n",
    "\n",
    "    labels.append(c)\n",
    "\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data.shape (30, 512, 2048, 3)\n",
      "labels.shape (30,)\n"
     ]
    }
   ],
   "source": [
    "data = np.array(data, dtype=\"float\")\n",
    "labels = np.array(labels)\n",
    "\n",
    "print('data.shape',data.shape)\n",
    "print('labels.shape',labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeli oluştur\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 512, 2048, 10)     760       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 512, 2048, 10)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 256, 1024, 10)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 256, 1024, 20)     5020      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 256, 1024, 20)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 128, 512, 20)      0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1310720)           0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 30)                39321630  \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 30)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 124       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 39,327,534\n",
      "Trainable params: 39,327,534\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoder.fit(labels)\n",
    "encoded_Y = encoder.transform(labels)\n",
    "dummy_Y = np_utils.to_categorical(encoded_Y)\n",
    "y = encoded_Y\n",
    "model = LeNet.build(width=2048, height=512, depth=3, classes=dummy_Y.shape[1])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeli yükle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath=\"03-malware-detection.hdf5\"\n",
    "\n",
    "model.load_weights(filepath)\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer='adam', metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 27 samples, validate on 3 samples\n",
      "Epoch 1/1\n",
      "27/27 [==============================] - 140s 5s/step - loss: 1.2662 - acc: 0.3704 - val_loss: 0.9849 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00001: loss improved from inf to 1.26623, saving model to 03-malware-detection.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c156c25a58>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(data, dummy_Y, verbose=1, epochs=1, batch_size=5, validation_split=0.1 , callbacks=callbacks_list )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model performansı"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = model.predict_classes(data)\n",
    "cm = confusion_matrix(encoded_Y, y_hat)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
