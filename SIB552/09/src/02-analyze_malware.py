import pandas as pd

import os
#os.environ['TF_CPP_MIN_LOG_LEVEL']='2'

import numpy as np
from sklearn.utils import shuffle
import nltk
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import classification_report,confusion_matrix,accuracy_score,roc_curve
from sklearn.cross_validation import train_test_split
from keras.models import Sequential
from keras.layers import Dense, Activation, Dropout
from sklearn.preprocessing import LabelEncoder
from keras.utils import np_utils
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix



def tokenize(text_token):
    tokens = nltk.word_tokenize(text_token)
    return tokens

fields = ["label", "api_call"]
D = pd.read_csv("02-CSDMC_API_Train.zip", names=fields, compression="zip")
D = shuffle(D)
print(D.head(10))

y = D["label"].as_matrix()
text = D["api_call"].tolist()

tfidf = TfidfVectorizer(tokenizer=tokenize, stop_words='english')
X = tfidf.fit_transform(text).todense()
print(X.shape)

'''
np.savetxt("tmp/tfidf.txt", X)
np.savetxt("tmp/y.txt", y, fmt="%d")

X = np.loadtxt("tmp/tfidf.txt")
y = np.loadtxt("tmp/y.txt", dtype=int)
'''


model = Sequential()
model.add(Dense(units=1000, input_dim=X.shape[1], activation='relu', kernel_initializer ='uniform'))
model.add(Dropout(0.2))
model.add(Dense(2000, activation='relu', kernel_initializer ='uniform'))
model.add(Dropout(0.2))
model.add(Dense(1000, activation='relu', kernel_initializer ='uniform'))
model.add(Dropout(0.2))
model.add(Dense(1, activation='sigmoid', kernel_initializer ='uniform'))
model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

history = model.fit(X, y, validation_split=0.1, epochs=20, batch_size=100, verbose=1)

loss_and_metrics = model.evaluate(X, y, batch_size=128)

print('\n'+'*'*100)
y_hat = model.predict_classes(X)
cm = confusion_matrix(y, y_hat)

print('*'*40)
print(cm)

# list all data in history
print(history.history.keys())
# summarize history for accuracy
plt.plot(history.history['acc'])
plt.plot(history.history['val_acc'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()
# summarize history for loss
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()
